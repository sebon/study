{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 문자, 코드 포인트, 바이트 표현\n",
    "- 이진 시퀀스의 고유한 특징 : bytes, bytearray, memoryview\n",
    "- 전체 유니코드 및 레거시 문자셋에 대한 코덱\n",
    "- 인코딩 에러를 피하고 다루기\n",
    "- 텍스트 파일을 다룰 때의 모범 사례\n",
    "- 기본 인코딩 및 표준 입출력 문제\n",
    "- 정규화를 이용한 안전한 유니코드 텍스트 비교\n",
    "- 정규화, 케이스 폴딩, 발음 구별 기호 강제 제거를 위한 유틸리티 함수\n",
    "- locale과 PyUCA 라이브러리를 이용한 유니코드 텍스트의 적절한 정렬\n",
    "- 유니코드 데이터베이스 안의 문자 메타데이터\n",
    "- str과 bytes를 다루는 이중모드 API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 문자 문제\n",
    "- 코드 포인트를 바이트로 변환하는 것을 __인코딩__, 바이트를 코드 포인트로 변환하는 것을 __디코딩__ 이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "b'caf\\xc3\\xa9'\n",
      "café\n"
     ]
    }
   ],
   "source": [
    "s = 'café'\n",
    "print (len(s))\n",
    "b= s.encode('utf8')\n",
    "print (b)\n",
    "len(b)\n",
    "print (b.decode('utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 바이트에 대한 기본 지식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'caf\\xc3\\xa9'\n",
      "99\n",
      "b'c'\n",
      "bytearray(b'caf\\xc3\\xa9')\n",
      "bytearray(b'\\xa9')\n"
     ]
    }
   ],
   "source": [
    "cafe = bytes ('café', encoding='utf8')\n",
    "print (cafe)\n",
    "print (cafe[0])\n",
    "print (cafe[:1])\n",
    "cafe_arr =  bytearray(cafe)\n",
    "print(cafe_arr)\n",
    "print (cafe_arr[-1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 화면에 출력 가능한 아스키 문자(공백에서 물결표(~)까지)는 아스키 문자 그대로 출력한다.\n",
    "- 탭, 개행 문자, 캐리지 리턴, 백슬래시(\\)는 이스케이프 시퀀스(\\t, \\n, \\r, \\\\\\\\)로 출력한다.\n",
    "- 그 외의 값은 널 바이트를 나타내는 \\x00처럼 16진수 이스케이프 시퀀스로 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'1K\\xce\\xa9'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes.fromhex('31 4B CE A9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xfe\\xff\\xff\\xff\\x00\\x00\\x01\\x00\\x02\\x00'\n"
     ]
    }
   ],
   "source": [
    "import array\n",
    "numbers = array.array('h', [-2, -1, 0, 1, 2])\n",
    "octets = bytes(numbers)\n",
    "print (octets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 구조체와 메모리 뷰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'filter.gif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-eaf349062b26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"<3s3sHH\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filter.gif'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'filter.gif'"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "fmt = \"<3s3sHH\"\n",
    "with open('filter.gif', 'rb') as fp:\n",
    "    img = memoryview(fp.read())\n",
    "header = img[:10]\n",
    "print (bytes(header))\n",
    "struct.unpack(fmt, header)\n",
    "del header\n",
    "del img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 기본 인코더/디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin_1\tb'El Ni\\xf1o'\n",
      "utf_8\tb'El Ni\\xc3\\xb1o'\n",
      "utf_16\tb'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00'\n"
     ]
    }
   ],
   "source": [
    "for codec in ['latin_1', 'utf_8', 'utf_16']:\n",
    "    print(codec, 'El Niño'.encode(codec), sep=\"\\t\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 인코딩/디코딩 문제 이해하기\n",
    "#### 4.4.1 UnicodeEoncdeError 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'S\\xc3\\xa3o Paulo'\n",
      "b'\\xff\\xfeS\\x00\\xe3\\x00o\\x00 \\x00P\\x00a\\x00u\\x00l\\x00o\\x00'\n",
      "b'S\\xe3o Paulo'\n",
      "b'So Paulo'\n",
      "b'S?o Paulo'\n",
      "b'S&#227;o Paulo'\n"
     ]
    }
   ],
   "source": [
    "city = 'São Paulo'\n",
    "print (city.encode('utf-8'))\n",
    "print (city.encode('utf-16'))\n",
    "print (city.encode('iso8859_1'))\n",
    "#print (city.encode('cp437'))\n",
    "print (city.encode('cp437', errors = 'ignore'))\n",
    "print (city.encode('cp437', errors = 'replace'))\n",
    "print (city.encode('cp437', errors = 'xmlcharrefreplace'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 UnicodeDecodeError 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montréal\n",
      "Montrιal\n",
      "MontrИal\n",
      "Montr�al\n"
     ]
    }
   ],
   "source": [
    "octets = b'Montr\\xe9al'\n",
    "print (octets.decode(\"cp1252\"))\n",
    "print (octets.decode(\"iso8859_7\"))\n",
    "print (octets.decode(\"koi8_r\"))\n",
    "#print (octets.decode(\"utf8\")) \n",
    "print (octets.decode(\"utf8\", errors='replace')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.3 예상과 달리 인코딩된 모듈을 로딩할 때 발생하는 SyntaxError\n",
    "#### 4.4.4 바이트 시퀀스의 인코딩 방식을 알아내는 방법\n",
    "#### 4.4.5 BOM : 유용한 깨진 문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xff\\xfeE\\x00l\\x00 \\x00N\\x00i\\x00\\xf1\\x00o\\x00'\n",
      "[255, 254, 69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]\n",
      "[69, 0, 108, 0, 32, 0, 78, 0, 105, 0, 241, 0, 111, 0]\n"
     ]
    }
   ],
   "source": [
    "u16 = 'El Niño'.encode('utf_16')\n",
    "print (u16)\n",
    "print (list(u16))\n",
    "u16le = 'El Niño'.encode('utf_16le')\n",
    "print (list(u16le))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.5  텍스트 파일 다루기\n",
    "- 텍스트 파일을 읽을 때는 언제나 encoding 인수를 명시적으로 지정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'café'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open ('cafe.txt', 'w', encoding =\"utf-8\") as wf:\n",
    "    wf.write('café')\n",
    "\n",
    "open('cafe.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 기본 인코딩 설정 : 정신 나간거 아냐?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " locale.getpreferredencoding() -> 'UTF-8'\n",
      "                 type(my_file) -> <class '_io.TextIOWrapper'>\n",
      "              my_file.encoding -> 'UTF-8'\n",
      "           sys.stdout.isatty() -> False\n",
      "           sys.stdout.encoding -> 'UTF-8'\n",
      "            sys.stdin.isatty() -> False\n",
      "            sys.stdin.encoding -> 'UTF-8'\n",
      "           sys.stderr.isatty() -> False\n",
      "           sys.stderr.encoding -> 'UTF-8'\n",
      "      sys.getdefaultencoding() -> 'utf-8'\n",
      "   sys.getfilesystemencoding() -> 'utf-8'\n"
     ]
    }
   ],
   "source": [
    "import sys, locale\n",
    "\n",
    "expressions = \"\"\"\n",
    "    locale.getpreferredencoding()\n",
    "    type(my_file)\n",
    "    my_file.encoding\n",
    "    sys.stdout.isatty()\n",
    "    sys.stdout.encoding\n",
    "    sys.stdin.isatty()\n",
    "    sys.stdin.encoding\n",
    "    sys.stderr.isatty()\n",
    "    sys.stderr.encoding\n",
    "    sys.getdefaultencoding()\n",
    "    sys.getfilesystemencoding()\n",
    "\"\"\"\n",
    "\n",
    "my_file = open('dummy', 'w')\n",
    "\n",
    "for expression in expressions.split():\n",
    "    value = eval(expression)\n",
    "    print (expression.rjust(30), \"->\" , repr(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 제대로 비교하기 위해 유니코드 정규화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "café café\n",
      "4 5\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "print (s1, s2)\n",
    "print (len(s1), len(s2))\n",
    "print (s1 ==s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5\n",
      "4 4\n",
      "5 5\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize\n",
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "print (len(s1), len(s2))\n",
    "print (len(normalize('NFC', s1)), len(normalize('NFC', s2)))\n",
    "print (len(normalize('NFD', s1)), len(normalize('NFD', s2)))\n",
    "print (normalize('NFC', s1) == normalize('NFC', s2))\n",
    "print (normalize('NFD', s1) == normalize('NFD', s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHM SIGN\n",
      "GREEK CAPITAL LETTER OMEGA\n",
      "False\n",
      "Ω Ω\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "ohm = '\\u2126'\n",
    "print (name(ohm))\n",
    "ohm_c = normalize('NFC', ohm)\n",
    "print (name(ohm_c))\n",
    "print (ohm == ohm_c)\n",
    "print (ohm, ohm_c)\n",
    "print (normalize('NFC', ohm) == normalize('NFC', ohm_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1⁄2\n",
      "42\n",
      "μ μ\n",
      "956 956\n",
      "GREEK SMALL LETTER MU GREEK SMALL LETTER MU\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import normalize, name\n",
    "half = '½'\n",
    "print (normalize('NFKC', half))\n",
    "\n",
    "four_squared = '42'\n",
    "print (normalize ('NFKC', four_squared))\n",
    "\n",
    "micro = 'μ'\n",
    "micro_kc = normalize('NFKC', micro)\n",
    "print (micro, micro_kc)\n",
    "print (ord(micro), ord(micro_kc))\n",
    "print (name(micro), name(micro_kc))\n",
    "#μ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.1 케이스 폴딩\n",
    "- 모든 텍스트를 소문자로 변환하는 연산, 약간의 변환을 동반한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREEK SMALL LETTER MU\n",
      "GREEK SMALL LETTER MU\n",
      "μ μ\n",
      "GREEK SMALL LETTER BETA\n",
      "β β\n"
     ]
    }
   ],
   "source": [
    "micro = 'μ'\n",
    "print (name(micro))\n",
    "micro_cf = micro.casefold()\n",
    "print (name(micro_cf))\n",
    "print (micro, micro_cf)\n",
    "eszett = 'β'\n",
    "print(name(eszett))\n",
    "eszett_cf = eszett.casefold()\n",
    "print (eszett, eszett_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6.2 정규화된 텍스트 매칭을 위한 유틸리티 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "s1 = 'café'\n",
    "s2 = 'cafe\\u0301'\n",
    "print (s1 == s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 4.6.3 극단적인 '정규화':발음 구별 기호 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "\n",
    "def shave_marks(txt):\n",
    "    \"\"\"Remove all diacritic marks\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)  # <1>\n",
    "    shaved = ''.join(c for c in norm_txt\n",
    "                     if not unicodedata.combining(c))  # <2>\n",
    "    return unicodedata.normalize('NFC', shaved)  # <3>\n",
    "# END SHAVE_MARKS\n",
    "\n",
    "# BEGIN SHAVE_MARKS_LATIN\n",
    "def shave_marks_latin(txt):\n",
    "    \"\"\"Remove all diacritic marks from Latin base characters\"\"\"\n",
    "    norm_txt = unicodedata.normalize('NFD', txt)  # <1>\n",
    "    latin_base = False\n",
    "    keepers = []\n",
    "    for c in norm_txt:\n",
    "        if unicodedata.combining(c) and latin_base:   # <2>\n",
    "            continue  # ignore diacritic on Latin base char\n",
    "        keepers.append(c)                             # <3>\n",
    "        # if it isn't combining char, it's a new base char\n",
    "        if not unicodedata.combining(c):              # <4>\n",
    "            latin_base = c in string.ascii_letters\n",
    "    shaved = ''.join(keepers)\n",
    "    return unicodedata.normalize('NFC', shaved)   # <5>\n",
    "# END SHAVE_MARKS_LATIN\n",
    "\n",
    "# BEGIN ASCIIZE\n",
    "single_map = str.maketrans(\"\"\"‚ƒ„†ˆ‹‘’“”•–—˜›\"\"\",  # <1>\n",
    "                           \"\"\"'f\"*^<''\"\"---~>\"\"\")\n",
    "\n",
    "multi_map = str.maketrans({  # <2>\n",
    "    '€': '<euro>',\n",
    "    '…': '...',\n",
    "    'Œ': 'OE',\n",
    "    '™': '(TM)',\n",
    "    'œ': 'oe',\n",
    "    '‰': '<per mille>',\n",
    "    '‡': '**',\n",
    "})\n",
    "\n",
    "multi_map.update(single_map)  # <3>\n",
    "\n",
    "\n",
    "def dewinize(txt):\n",
    "    \"\"\"Replace Win1252 symbols with ASCII chars or sequences\"\"\"\n",
    "    return txt.translate(multi_map)  # <4>\n",
    "\n",
    "\n",
    "def asciize(txt):\n",
    "    no_marks = shave_marks_latin(dewinize(txt))     # <5>\n",
    "    no_marks = no_marks.replace('ß', 'ss')          # <6>\n",
    "    return unicodedata.normalize('NFKC', no_marks)  # <7>\n",
    "# END ASCIIZE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.7 유니코드 텍스트 정렬하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "locale.setlocale(locale.LC_COLLATE, 'pt_BR.UTF-8')\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "sorted_fruits = sorted(fruits, key=locale.strxfrm)\n",
    "print (sorted_fruits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['açaí', 'acerola', 'atemoia', 'cajá', 'caju']\n"
     ]
    }
   ],
   "source": [
    "import pyuca\n",
    "coll = pyuca.Collator()\n",
    "fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']\n",
    "soreted_fruits = sorted(fruits, key =coll.sort_key)\n",
    "print (sorted_fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4.8 유니코드 데이터 베이스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U+0031\t  1   \tre_dig\tisdig\tisnum\t 1.00\tDIGIT ONE\n",
      "U+00bc\t  ¼   \t-\t-\tisnum\t 0.25\tVULGAR FRACTION ONE QUARTER\n",
      "U+00b2\t  ²   \t-\tisdig\tisnum\t 2.00\tSUPERSCRIPT TWO\n",
      "U+0969\t  ३   \tre_dig\tisdig\tisnum\t 3.00\tDEVANAGARI DIGIT THREE\n",
      "U+136b\t  ፫   \t-\tisdig\tisnum\t 3.00\tETHIOPIC DIGIT THREE\n",
      "U+216b\t  Ⅻ   \t-\t-\tisnum\t12.00\tROMAN NUMERAL TWELVE\n",
      "U+2466\t  ⑦   \t-\tisdig\tisnum\t 7.00\tCIRCLED DIGIT SEVEN\n",
      "U+2480\t  ⒀   \t-\t-\tisnum\t13.00\tPARENTHESIZED NUMBER THIRTEEN\n",
      "U+3285\t  ㊅   \t-\t-\tisnum\t 6.00\tCIRCLED IDEOGRAPH SIX\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "re_digit = re.compile(r'\\d')\n",
    "sample = '1\\xbc\\xb2\\u0969\\u136b\\u216b\\u2466\\u2480\\u3285'\n",
    "\n",
    "for char in sample:\n",
    "    print ( 'U+%04x' % ord(char),\n",
    "            char.center(6),\n",
    "           're_dig' if re_digit.match(char) else '-',\n",
    "           'isdig' if char.isdigit() else '-',\n",
    "           'isnum' if char.isnumeric() else '-',\n",
    "           format(unicodedata.numeric(char), '5.2f'),\n",
    "           unicodedata.name(char),\n",
    "           sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.9 이중 모드 str 및 bytes API\n",
    "#### 4.9.1 정규 표현식에서의 str과 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "'Ramanujan saw ௧௭௨௯ as 1729 = 1³ + 12³ = 9³ + 10³.'\n",
      "Numbers\n",
      "    str  : ['௧௭௨௯', '1729', '1', '12', '9', '10']\n",
      "    bytes: [b'1729', b'1', b'12', b'9', b'10']\n",
      "Words\n",
      "    str  : ['Ramanujan', 'saw', '௧௭௨௯', 'as', '1729', '1³', '12³', '9³', '10³']\n",
      "    bytes: [b'Ramanujan', b'saw', b'as', b'1729', b'1', b'12', b'9', b'10']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re_numbers_str = re.compile(r'\\d+')\n",
    "re_words_str = re.compile(r'\\w+')\n",
    "re_numbers_bytes = re.compile(rb'\\d+')\n",
    "re_words_bytes = re.compile(rb'\\w+')\n",
    "\n",
    "text_str = (\"Ramanujan saw \\u0be7\\u0bed\\u0be8\\u0bef\"\n",
    "            \" as 1729 = 1³ + 12³ = 9³ + 10³.\")\n",
    "\n",
    "text_bytes = text_str.encode(\"utf_8\")\n",
    "\n",
    "print (\"Text\", repr(text_str), sep='\\n')\n",
    "print ('Numbers')\n",
    "print ('    str  :', re_numbers_str.findall(text_str))\n",
    "print ('    bytes:', re_numbers_bytes.findall(text_bytes))\n",
    "print ('Words')\n",
    "print ('    str  :', re_words_str.findall(text_str))\n",
    "print ('    bytes:', re_words_bytes.findall(text_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.9.2 os 모듈 함수에서 str과 bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'CH1. 파이썬 데이터 모델.ipynb', 'CH.2 시퀀스.ipynb', 'bisect_demo.py', 'floats.bin', 'CH3. 딕셔너리와 집합.ipynb', 'zen.txt', 'CH4. 텍스트와 바이트.ipynb', 'cafe.txt', 'dummy']\n",
      "[b'.ipynb_checkpoints', b'CH1. \\xed\\x8c\\x8c\\xec\\x9d\\xb4\\xec\\x8d\\xac \\xeb\\x8d\\xb0\\xec\\x9d\\xb4\\xed\\x84\\xb0 \\xeb\\xaa\\xa8\\xeb\\x8d\\xb8.ipynb', b'CH.2 \\xec\\x8b\\x9c\\xed\\x80\\x80\\xec\\x8a\\xa4.ipynb', b'bisect_demo.py', b'floats.bin', b'CH3. \\xeb\\x94\\x95\\xec\\x85\\x94\\xeb\\x84\\x88\\xeb\\xa6\\xac\\xec\\x99\\x80 \\xec\\xa7\\x91\\xed\\x95\\xa9.ipynb', b'zen.txt', b'CH4. \\xed\\x85\\x8d\\xec\\x8a\\xa4\\xed\\x8a\\xb8\\xec\\x99\\x80 \\xeb\\xb0\\x94\\xec\\x9d\\xb4\\xed\\x8a\\xb8.ipynb', b'cafe.txt', b'dummy']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print (os.listdir('.'))\n",
    "print (os.listdir(b'.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (os.listdir('.'))\n",
    "print (os.listdir(b'.'))\n",
    "\n",
    "pi_name_bytes = os.listdir(b'.')[1]\n",
    "pi_name_str = pi_name_bytes.decode('ascii', 'surrogateescape')\n",
    "print (pi_name_str)\n",
    "print (pi_name_str.encode('ascii', 'surrogateescape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
